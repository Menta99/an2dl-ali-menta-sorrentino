{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"Multiclass_Segmentation_customA.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"I5FnwOggnFIl"},"source":["from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tOBDSA9BnFIx"},"source":["# Imports\n","import os\n","import tensorflow as tf\n","import numpy as np\n","import json\n","from PIL import Image\n","import time\n","from datetime import datetime\n","from matplotlib import cm\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline\n","\n","# Global variables\n","TRAIN = True\n","SEED = 1234\n","tf.random.set_seed(SEED)  \n","cwd = os.getcwd()\n","num_classes = 3\n","bs = 2\n","img_h = 1024\n","img_w = img_h\n","orig_img_h = 1536\n","orig_img_w = 2048"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z8bhsWQnnU-i"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mH3lzlVqnFI2"},"source":["# Example: Image Segmentation\n","## Build segmentation"]},{"cell_type":"code","metadata":{"id":"4N88wG50nFI3"},"source":["# ImageDataGenerator\n","# ------------------\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","apply_data_augmentation = True\n","\n","# Create training ImageDataGenerator object\n","# We need two different generators for images and corresponding masks\n","if apply_data_augmentation:\n","    img_data_gen = ImageDataGenerator(featurewise_center=True,\n","                                      featurewise_std_normalization=True,\n","                                      rotation_range=10,\n","                                      width_shift_range=10,\n","                                      height_shift_range=10,\n","                                      zoom_range=0.3,\n","                                      horizontal_flip=True,\n","                                      vertical_flip=True,\n","                                      fill_mode='reflect')\n","    mask_data_gen = ImageDataGenerator(featurewise_center=True,\n","                                       featurewise_std_normalization=True,\n","                                       rotation_range=10,\n","                                       width_shift_range=10,\n","                                       height_shift_range=10,\n","                                       zoom_range=0.3,\n","                                       horizontal_flip=True,\n","                                       vertical_flip=True,\n","                                       fill_mode='reflect')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hsieZk4aKhm6"},"source":["from PIL import Image\n","\n","class CustomDataset(tf.keras.utils.Sequence):\n","\n","  def __init__(self, dataset_dir, which_subset, img_generator=None, mask_generator=None, \n","               preprocessing_function=None, out_shape=[img_h, img_w]):\n","    '''\n","      Taking images according to input dataset (train or val)\n","    '''\n","    if which_subset == 'training':\n","      subset_file = os.path.join(dataset_dir, 'Splits', 'train.txt')\n","    elif which_subset == 'validation':\n","      subset_file = os.path.join(dataset_dir, 'Splits', 'val.txt')\n","    \n","    with open(subset_file, 'r') as f:\n","      lines = f.readlines()\n","    \n","    subset_filenames = []\n","    for line in lines:\n","      subset_filenames.append(line.strip()) \n","\n","    self.which_subset = which_subset\n","    self.dataset_dir = dataset_dir\n","    self.subset_filenames = subset_filenames\n","    self.img_generator = img_generator\n","    self.mask_generator = mask_generator\n","    self.preprocessing_function = preprocessing_function\n","    self.out_shape = out_shape\n","\n","  def __len__(self):\n","    return len(self.subset_filenames)\n","\n","  def _read_rgb_mask(self, img_path):\n","    '''\n","    img_path: path to the mask file\n","    Returns the numpy array containing target values\n","    '''\n","\n","    mask_img = Image.open(img_path)\n","    mask_img = mask_img.resize(self.out_shape, resample=Image.NEAREST)\n","    mask_arr = np.array(mask_img)\n","\n","    new_mask_arr = np.zeros(mask_arr.shape[:2], dtype=mask_arr.dtype)\n","\n","    # Use RGB dictionary in 'RGBtoTarget.txt' to convert RGB to target\n","    new_mask_arr[np.where(np.all(mask_arr == [216, 124, 18], axis=-1))] = 0 # border as bg\n","    new_mask_arr[np.where(np.all(mask_arr == [255, 255, 255], axis=-1))] = 1\n","    new_mask_arr[np.where(np.all(mask_arr == [216, 67, 82], axis=-1))] = 2\n","\n","    return new_mask_arr\n","\n","  def __getitem__(self, index):\n","    # Read Image\n","    curr_filename = self.subset_filenames[index]\n","    img = Image.open(os.path.join(self.dataset_dir, 'Images', curr_filename + '.jpg'))\n","    \n","    # Resize image and mask\n","    img = img.resize(self.out_shape)\n","    \n","    img_arr = np.array(img)\n","\n","    mask_arr = self._read_rgb_mask(os.path.join(self.dataset_dir, 'Masks', curr_filename + '.png'))\n","\n","    mask_arr = np.expand_dims(mask_arr, -1)\n","\n","    if self.which_subset == 'training':\n","      if self.img_generator is not None and self.mask_generator is not None:\n","        img_t = self.img_generator.get_random_transform(img_arr.shape, seed=SEED)\n","        mask_t = self.mask_generator.get_random_transform(mask_arr.shape, seed=SEED)\n","        img_arr = self.img_generator.apply_transform(img_arr, img_t)\n","\n","        out_mask = np.zeros_like(mask_arr)\n","        for c in np.unique(mask_arr):\n","          if c > 0:\n","            curr_class_arr = np.float32(mask_arr == c)\n","            curr_class_arr = self.mask_generator.apply_transform(curr_class_arr, mask_t)\n","            # from [0, 1] to {0, 1}\n","            curr_class_arr = np.uint8(curr_class_arr)\n","            # recover original class\n","            curr_class_arr = curr_class_arr * c \n","            out_mask += curr_class_arr\n","    else:\n","      out_mask = mask_arr\n","    \n","    if self.preprocessing_function is not None:\n","        img_arr = self.preprocessing_function(img_arr)\n","\n","    return img_arr, np.float32(out_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TyrdiIh_PWjB"},"source":["# Dataset\n","dataset_dir = os.path.join(cwd, 'drive/MyDrive/Assignment_2/Dataset')\n","dataset_dir = os.path.join(dataset_dir, 'BipBip')\n","\n","dataset = CustomDataset(dataset_dir, 'training', \n","                        img_generator=img_data_gen, \n","                        mask_generator=mask_data_gen)\n","dataset_valid = CustomDataset(dataset_dir, 'validation')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"usz5SKPeQrOE"},"source":["# Train and Valid datasets\n","train_dataset = tf.data.Dataset.from_generator(lambda: dataset,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n","train_dataset = train_dataset.batch(bs)\n","train_dataset = train_dataset.repeat()\n","\n","\n","valid_dataset = tf.data.Dataset.from_generator(lambda: dataset_valid,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n","valid_dataset = valid_dataset.batch(bs)\n","valid_dataset = valid_dataset.repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MyJEKDG1A9Hw"},"source":["# Let's test data generator\n","# -------------------------\n","import time\n","from matplotlib import cm\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","# Assign a color to each class\n","evenly_spaced_interval = np.linspace(0, 1, 3)\n","colors = [cm.rainbow(x) for x in evenly_spaced_interval]\n","\n","iterator = iter(valid_dataset)\n","\n","fig, ax = plt.subplots(1, 2)\n","\n","augmented_img, target = next(iterator)\n","augmented_img = augmented_img[0]   # First element\n","augmented_img = augmented_img  # denormalize\n","\n","target = np.array(target[0, ..., 0])   # First element (squeezing channel dimension)\n","\n","print(np.unique(target))\n","\n","target_img = np.zeros([target.shape[0], target.shape[1], 3])\n","\n","target_img[np.where(target == 0)] = [0, 0, 0]\n","for i in range(1, num_classes):\n","  target_img[np.where(target == i)] = np.array(colors[i-1])[:3] * 255\n","\n","ax[0].imshow(np.uint8(augmented_img))\n","ax[1].imshow(np.uint8(target_img))\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JA1TGlOMnFJM"},"source":["## Convolutional Neural Network (CNN)\n","### Encoder-Decoder"]},{"cell_type":"code","metadata":{"id":"BvsdiF0TFTbt"},"source":["# Create Model\n","# ------------\n","\n","def create_model(depth, start_f, num_classes, dynamic_input_shape):\n","\n","    model = tf.keras.Sequential()\n","    \n","    # Encoder\n","    # -------\n","    for i in range(depth):\n","        \n","        if i == 0:\n","            if dynamic_input_shape:\n","                input_shape = [None, None, 3]\n","            else:\n","                input_shape = [img_h, img_w, 3]\n","        else:\n","            input_shape=[None]\n","        \n","        model.add(tf.keras.layers.Conv2D(filters=start_f, \n","                                         kernel_size=(3, 3),\n","                                         strides=(1, 1),\n","                                         padding='same',\n","                                         input_shape=input_shape,\n","                                        ))\n","        model.add(tf.keras.layers.BatchNormalization());\n","        model.add(tf.keras.layers.ReLU())\n","        model.add(tf.keras.layers.Dropout(0.2, seed=SEED))\n","        model.add(tf.keras.layers.Conv2D(filters=start_f, \n","                                         kernel_size=(3, 3),\n","                                         strides=(1, 1),\n","                                         padding='same'\n","                                        ))\n","        model.add(tf.keras.layers.ReLU())\n","        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n","\n","        start_f *= 2\n","\n","    # Bottleneck\n","    model.add(tf.keras.layers.Conv2D(filters=start_f, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n","    model.add(tf.keras.layers.BatchNormalization());\n","    model.add(tf.keras.layers.ReLU())\n","    model.add(tf.keras.layers.Dropout(0.2, seed=SEED))\n","    model.add(tf.keras.layers.Conv2D(filters=start_f, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n","    model.add(tf.keras.layers.ReLU())\n","    \n","    start_f = start_f // 2\n","    \n","    # Decoder\n","    # -------\n","    for i in range(depth):\n","        model.add(tf.keras.layers.UpSampling2D(2, interpolation='bilinear'))\n","        model.add(tf.keras.layers.Conv2D(filters=start_f,\n","                                         kernel_size=(3, 3),\n","                                         strides=(1, 1),\n","                                         padding='same'))\n","        model.add(tf.keras.layers.BatchNormalization());\n","        model.add(tf.keras.layers.ReLU())\n","        model.add(tf.keras.layers.Dropout(0.2, seed=SEED))\n","\n","        start_f = start_f // 2\n","\n","    # Prediction Layer\n","    # ----------------\n","    model.add(tf.keras.layers.Conv2D(filters=num_classes,\n","                                     kernel_size=(1, 1),\n","                                     strides=(1, 1),\n","                                     padding='same',\n","                                     activation='softmax'))\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"k97OK6CRnFJS"},"source":["model = create_model(depth=4, \n","                     start_f=32, \n","                     num_classes=num_classes,\n","                     dynamic_input_shape=False)\n","\n","# Visualize created model as a table\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NGzh16WTnFJW"},"source":["## Prepare the model for training"]},{"cell_type":"code","metadata":{"id":"9MlmYGVMnFJW"},"source":["# Optimization params\n","# -------------------\n","\n","# Loss\n","# Sparse Categorical Crossentropy to use integers (mask) instead of one-hot encoded labels\n","loss = tf.keras.losses.SparseCategoricalCrossentropy() \n","lr = 1e-4\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","# -------------------\n","\n","# Here we define the intersection over union for each class in the batch.\n","# Then we compute the final iou as the mean over classes\n","def meanIoU(y_true, y_pred):\n","    # get predicted class from softmax\n","    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n","\n","    per_class_iou = []\n","\n","    for i in range(1,num_classes): # exclude the background class 0\n","      # Get prediction and target related to only a single class (i)\n","      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n","      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n","      intersection = tf.reduce_sum(class_true * class_pred)\n","      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n","\n","      iou = i * (intersection + 1e-7) / (union + 1e-7)\n","      per_class_iou.append(iou)\n","      \n","    # The meaniou has different weights for different classes\n","    # It is therefore noramlized like a weighted sum on IoU\n","    return tf.reduce_sum(per_class_iou) / 3\n","\n","# Validation metrics\n","# ------------------\n","metrics = ['accuracy', meanIoU]\n","# ------------------\n","\n","# Compile Model\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PA6D_TBknFJZ"},"source":["## Training with callbacks"]},{"cell_type":"code","metadata":{"id":"Qc9-EgcyFRvG"},"source":["%reload_ext tensorboard\n","%tensorboard --logdir /content/drive/My\\ Drive/Assignment_2/Log"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"3XiwaKZhnFJa"},"source":["# Performing this step only if in training stage (and not using this notebook to make predicitons only)\n","if(TRAIN):\n","  exps_dir = os.path.join(cwd, 'drive/My Drive/Assignment_2/Log', 'multiclass_segmentation_experiments')\n","  if not os.path.exists(exps_dir):\n","      os.makedirs(exps_dir)\n","\n","  now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","  model_name = 'CNN'\n","\n","  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n","  if not os.path.exists(exp_dir):\n","      os.makedirs(exp_dir)\n","      \n","  callbacks = []\n","\n","  # Model checkpoint\n","  # ----------------\n","  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","  if not os.path.exists(ckpt_dir):\n","      os.makedirs(ckpt_dir)\n","\n","  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n","                                                    save_weights_only=True, save_best_only=True)  # False to save the model directly\n","  callbacks.append(ckpt_callback)\n","\n","  # Visualize Learning on Tensorboard\n","  # ---------------------------------\n","  tb_dir = os.path.join(exp_dir, 'tb_logs')\n","  if not os.path.exists(tb_dir):\n","      os.makedirs(tb_dir)\n","      \n","  # By default shows losses and metrics for both training and validation\n","  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n","                                              profile_batch=0,\n","                                              histogram_freq=0)  # if 1 shows weights histograms\n","  callbacks.append(tb_callback)\n","\n","  # Reduce on Plateu\n","  # --------------\n","  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1, cooldown=0)\n","  callbacks.append(reduce_lr)\n","\n","  # Early Stopping\n","  # --------------\n","  early_stop = True\n","  if early_stop:\n","      es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","      callbacks.append(es_callback)\n","\n","\n","  model.fit(x=train_dataset,\n","            epochs=100,  #### set repeat in training dataset\n","            steps_per_epoch=len(dataset), # len dataset is not normalized by bs. This means that the training and validation sets are seen 2 times because of the function repeat\n","            validation_data=valid_dataset,\n","            validation_steps=len(dataset_valid), \n","            callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-JUMMkS9eyQW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6ffc8306-b05b-4bf1-88f0-905b14243bc7"},"source":["if(TRAIN):\n","  # Save the model\n","  model.save('/content/drive/My Drive/Assignment_2/Saved Models/CustomE')\n","else:\n","  # Load model to make prediciton\n","  model = tf.keras.models.load_model('/content/drive/My Drive/Assignment_2/Saved Models/CustomA', custom_objects={'meanIoU':meanIoU})"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /content/drive/My Drive/Assignment_2/Saved Models/CustomE/assets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8LXX9CqnnEv","outputId":"6e33f04f-56dd-45ae-a42f-9fbf77e9b79a"},"source":["# Optional\n","# Instead of loading the model it is possible to just load weights\n","# from checkpoint.\n","\n","#model.load_weights('/content/drive/My Drive/Assignment_2/Log/multiclass_segmentation_experiments/CNN_Dec19_10-57-23/ckpts/cp_21.ckpt')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7efe01e40668>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"EZ1Yl-InnFJd"},"source":["## Test model"]},{"cell_type":"markdown","metadata":{"id":"WuVw1q_NnFJh"},"source":["## Compute prediction"]},{"cell_type":"code","metadata":{"id":"Y_qO-WKAYPDT"},"source":["# Testing visually accuracy of predicitons\n","\n","fig, ax = plt.subplots(1, 3, figsize=(8, 8))\n","fig.show()\n","image, target = next(iterator)\n","\n","image = image[0]\n","target = target[0, ..., 0]\n","\n","out_sigmoid = model.predict(x=tf.expand_dims(image, 0))\n","\n","# Get predicted class as the index corresponding to the maximum value in the vector probability\n","# predicted_class = tf.cast(out_sigmoid > score_th, tf.int32)\n","# predicted_class = predicted_class[0, ..., 0]\n","predicted_class = tf.argmax(out_sigmoid, -1)\n","\n","out_sigmoid.shape\n","\n","predicted_class = predicted_class[0, ...]\n","\n","# Assign colors (just for visualization)\n","target_img = np.zeros([target.shape[0], target.shape[1], 3])\n","prediction_img = np.zeros([target.shape[0], target.shape[1], 3])\n","\n","target_img[np.where(target == 0)] = [0, 0, 0]\n","for i in range(1, 3):\n","  target_img[np.where(target == i)] = np.array(colors[i-1])[:3] * 255\n","\n","prediction_img[np.where(predicted_class == 0)] = [0, 0, 0]\n","for i in range(1, 3):\n","  prediction_img[np.where(predicted_class == i)] = np.array(colors[i-1])[:3] * 255\n","\n","ax[0].imshow(np.uint8(image))\n","ax[1].imshow(np.uint8(target_img))\n","ax[2].imshow(np.uint8(prediction_img))\n","\n","fig.canvas.draw()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dYxCTuJ587md"},"source":["import cv2\n","def rle_encode(img):\n","    '''\n","    img: numpy array, 1 - foreground, 0 - background\n","    Returns run length as string formatted\n","    '''\n","    pixels = img.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)\n","\n","################################################################################\n","################################################################################\n","\n","def update_dictionary(submission_dict, img, img_name, team, crop,):\n","  submission_dict[img_name] = {}\n","  submission_dict[img_name]['shape'] = img.shape\n","  submission_dict[img_name]['team'] = team\n","  submission_dict[img_name]['crop'] = crop\n","  submission_dict[img_name]['segmentation'] = {}\n","\n","  # RLE encoding  \n","  # crop\n","  rle_encoded_crop = rle_encode(img == 1)\n","  # weed\n","  rle_encoded_weed = rle_encode(img == 2)\n","\n","  submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\n","  submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\n","  # Finally, save the results into the submission.json file\n","  return submission_dict\n","\n","################################################################################\n","################################################################################\n","\n","def trim_filenames(test_gen):\n","  filenames = test_gen.filenames\n","  prova = [e[7:] for e in filenames]\n","  filenames = []\n","  for file in prova:\n","    filenames.append(file.split(\".\")[0])\n","  return filenames\n","\n","################################################################################\n","################################################################################\n","\n","def create_prediction(category, dictionary):\n","  team = category.split('/')[0]\n","  crop = category.split('/')[1]\n","  path = os.path.join(cwd, '/content/drive/My Drive/Assignment_2/Dataset/All/Test_Dev', category)\n","  print(path)\n","  test_data_gen = ImageDataGenerator()\n","  test_gen = test_data_gen.flow_from_directory(path,\n","                                               target_size=(img_h,img_w),\n","                                               color_mode=\"rgb\",\n","                                               batch_size=1, \n","                                               class_mode='categorical',\n","                                               classes=None,\n","                                               shuffle=False,\n","                                               seed=SEED)\n","  \n","  filenames = trim_filenames(test_gen)\n","  prediction = model.predict(test_gen)\n","  for i in range(len(filenames)):\n","    arr_ = np.squeeze(prediction[i])\n","    resize_img = cv2.resize(arr_, dsize=(orig_img_w, orig_img_h), interpolation=cv2.INTER_NEAREST)\n","    predicted_class = tf.argmax(resize_img, -1)\n","    result = np.array(predicted_class)\n","    dictionary = update_dictionary(dictionary, result, filenames[i], team, crop)\n","    #create_json(result, filenames[i], team, crop, os.path.join(cwd, 'drive/MyDrive/ANN/submission.json'))\n","  \n","  return dictionary\n","\n","################################################################################\n","################################################################################\n","\n","def iterate_dataset(directories_path):\n","  with open(directories_path, 'r') as f:\n","    paths = [line.rstrip() for line in f.readlines()]\n","    dictionary = {}\n","    for name in paths:\n","      dictionary = create_prediction(name, dictionary)\n","    with open(os.path.join(cwd, 'drive/MyDrive/Assignment_2/Results/submission.json'), 'w') as f:\n","      json.dump(dictionary, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"00lAYG73Cm4T"},"source":["iterate_dataset(os.path.join(cwd, 'drive/MyDrive/Assignment_2/Results/directories.txt'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EA0U6Urk5lKX"},"source":["## Zipping file"]},{"cell_type":"code","metadata":{"id":"U2ybvYwhK-1V"},"source":["%cd drive/MyDrive/Assignment_2/Results/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JWtEBD8RYGNm"},"source":["from zipfile import ZipFile\n","\n","with ZipFile('submission.zip', 'w') as zipObj:\n","  zipObj.write('submission.json')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLqVirHDLAMK"},"source":["# resetting workign directory\n","%cd /content/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tkzr_4nFLPqY"},"source":[""],"execution_count":null,"outputs":[]}]}